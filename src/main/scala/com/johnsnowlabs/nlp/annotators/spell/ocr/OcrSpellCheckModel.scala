package com.johnsnowlabs.nlp.annotators.spell.ocr

import com.github.liblevenshtein.transducer.{Candidate, ITransducer}
import com.johnsnowlabs.ml.tensorflow.{TensorflowSpell, TensorflowWrapper}
import com.johnsnowlabs.nlp.annotators.assertion.dl.ReadTensorflowModel
import com.johnsnowlabs.nlp.annotators.ner.Verbose
import com.johnsnowlabs.nlp.{Annotation, AnnotatorModel, AnnotatorType}
import org.apache.spark.ml.util.Identifiable
import org.apache.spark.sql.SparkSession

class OcrSpellCheckModel(override val uid: String) extends AnnotatorModel[OcrSpellCheckModel] with ReadTensorflowModel {

  override val tfFile: String = "good_model"

  private var tensorflow:TensorflowWrapper = null

  private var transducer:ITransducer[Candidate] = null

  private var specialClassesTransducers: Seq[ITransducer[Candidate]] = null

  private var vocabFreq: Predef.Map[String, Double] = null

  private var vocabIds: Predef.Map[String, Int] = null

  def readModel(path: String, spark: SparkSession, suffix: String): this.type = {
    tensorflow = readTensorflowModel(path, spark, suffix)
    this
  }

  @transient
  private var _model: TensorflowSpell = null

  def model: TensorflowSpell = {
    if (_model == null) {
      require(tensorflow != null, "Tensorflow must be set before usage. Use method setTensorflow() for it.")

      _model = new TensorflowSpell(
        tensorflow,
        Verbose.Silent)
    }
    _model
  }


  def setTensorflow(tf: TensorflowWrapper): OcrSpellCheckModel = {
    tensorflow = tf
    this
  }


  def setVocabTransducer(trans:ITransducer[Candidate]) = {
    transducer = trans
    this
  }

  def setVocabFreq(v: Map[String, Double]) = {
    vocabFreq = v
    this
  }

  def setVocabIds(v: Map[String, Int]) = {
    vocabIds = v
    this
  }

  def setSpecialClassesTransducers(transducers: Seq[ITransducer[Candidate]]) = {
    specialClassesTransducers = transducers
    this
  }

  def getCost(path: Array[Int], pathCost:Double, state: Int) = {

    model.predict(Array(path))
  }

  def decodeViterbi(trellis: Array[Array[(String, Double)]]):(Array[Int], Double) = {

    // encode words with ids
    val encTrellis = Array(Array((vocabIds("_BOS_"), 1.0))) ++
          trellis.map(_.map{case (word, weight) => (vocabIds.getOrElse(word, vocabIds("_UNK_")), weight)}) ++
          Array(Array((vocabIds("_EOS_"), 1.0)))

    // init
    var paths = Array(Array(vocabIds("_BOS_")))
    var costs = Array(1.0) // cost for each of the paths
    var ppls = Array(1.0) // perplexities for each path

    for(i <- 1 to encTrellis.length - 1) {

      var newPaths = Array(Array[Int]())
      var newCosts = Array[Double]()
      var newPpl = Array[Double]()

      for {(state, wcost) <- encTrellis(i)} {
        var minCost = Double.MaxValue
        var minPath = Array[Int]()
        var minPpl = Double.MaxValue

        for ((path, pathCost, pathPpl) <- (paths, costs, ppls).zipped) {
          // compute cost to arrive to this 'state' coming from that 'path'
          model
          val ppl = _model.predict(Array(path :+ state)).head
          val dppl = ppl - pathPpl
          val cost = pathCost + dppl * wcost
          if (cost < minCost){
            minCost = cost
            minPath = path :+ state
            minPpl = ppl
          }
        }
        newPaths = newPaths :+ minPath
        newCosts = newCosts :+ minCost
        newPpl = newPpl :+ minPpl
      }
      paths = newPaths
      costs = newCosts
      ppls = newPpl
    }

    (paths.zip(costs).minBy(_._2)._1, 0.0)
  }

  /**
    * takes a document and annotations and produces new annotations of this annotator's annotation type
    *
    * @param annotations Annotations that correspond to inputAnnotationCols generated by previous annotators if any
    * @return any number of annotations processed for every input annotation. Not necessary one to one relationship
    */
  override def annotate(annotations: Seq[Annotation]): Seq[Annotation] = {
    import scala.collection.JavaConversions._
    val allTransducers = specialClassesTransducers :+ transducer


    annotations.map{ annotation =>
      val trellis:Array[Array[(String, Double)]] = annotation.result.split(" ").map { token =>
        // ask each token class for candidates, keep the one with lower cost
        val candidates = allTransducers.flatMap(_.transduce(token, 2))
        val min = candidates.map(_.distance).min

        // TODO remove hardcoded normalization
        val candW = candidates.map{ c =>
          val weight = -vocabFreq.getOrElse(c.term, Double.MaxValue) / 60.0 + c.distance.toDouble / token.size
          (c.term, weight)
        }.sortBy(_._2).take(10) // TODO: this should be a Param

        println(s"""$token -> ${candW.toList.take(7)}""")
        candW.toArray
      }

      val (decodedPath, cost) = decodeViterbi(trellis)

      annotation.copy(result = decodedPath.mkString(" "),
        metadata = annotation.metadata + ("score" -> cost.toString))
    }
  }

  def this() = this(Identifiable.randomUID("SPELL"))

  /** Annotator reference id. Used to identify elements in metadata or to refer to this annotator type */
  override val requiredAnnotatorTypes: Array[String] = Array(AnnotatorType.TOKEN)
  override val annotatorType: AnnotatorType = AnnotatorType.TOKEN

}
